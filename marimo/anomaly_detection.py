import marimo

__generated_with = "0.5.2"
app = marimo.App(width="full")


@app.cell
def __(mo):
    mo.md("""
    # æ¬¡ä¸–ä»£ã®Jupyter notebookã€Œmarimoã€ã§ä½œã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ‡ãƒ¼ã‚¿åˆ†æå ±å‘Šæ›¸~Pridictive Maintainance Dataset~
    * ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨å‰å‡¦ç†ãƒ»æ‰‹æ³•ã‚’é¸æŠã—ãªãŒã‚‰ç•°å¸¸æ¤œçŸ¥ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def __(mo):
    f = mo.ui.file_browser(multiple=False)
    mo.vstack([
        mo.md("""
            * ç•°å¸¸æ¤œçŸ¥ã‚’è¡Œã†csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ä»¥ä¸‹ã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚
                * 100MBã®å®¹é‡åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚
                * .csvãƒ•ã‚¡ã‚¤ãƒ«ã«é™ã‚Šã¾ã™ã€‚
                * ç•°å¸¸å€¤ã®ãƒ•ãƒ©ã‚°ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"""),
               f])
    return f,


@app.cell
def __(e, f, mo, pd):
    _stack_mo_list = []
    READ_DATA = False
    if f.path() != None:
        if f.name().split('.')[-1] not in ['csv', 'CSV']:
            _stack_mo_list.append(mo.md('ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ãŒcsvã¾ãŸã¯CSVã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚').callout('alert'))
        else:
            try:
                df = pd.read_csv(f.path(), index_col=0)
                _stack_mo_list = [mo.md('æ­£å¸¸ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ').callout('info'),
                                  mo.as_html(df.head())]
                READ_DATA = True
            except Exception() as e:
                _stack_mo_list.append(mo.md(f'ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}').callout('alert'))
    mo.vstack(_stack_mo_list)
    return READ_DATA, df


@app.cell
def __(mo):
    code = mo.ui.code_editor(label="Code Editor: ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å¿…è¦ãªå‡¦ç†ãŒã‚ã‚Œã°mainé–¢æ•°å†…ã«è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚", 
                             language="python",
                             value=
    """# é–¢æ•°åã¯å¤‰ãˆãªã„
    def main(df):
      # ====== ã“ã“ã‚’ç·¨é›†ã™ã‚‹ =====
      # ä¾‹: machine maintainance ãƒ‡ãƒ¼ã‚¿ã ã¨[hoge]ã‚’å‰Šé™¤ã™ã‚‹
      df.columns = [c.split('[')[0].strip() for c in df.columns]
      return df"""
    )
    mo.as_html(code)
    return code,


@app.cell
def __(READ_DATA, code, df, main):
    if READ_DATA:
        print(code.value)
        exec(code.value)
        code_prep_df = main(df)
    return code_prep_df,


@app.cell
def __(READ_DATA, code_prep_df, mo):
    _stack_mo_list = []
    if READ_DATA:
        transformed_df = mo.ui.dataframe(code_prep_df)
        _stack_mo_list.append(
            mo.md('## marimoã®æ©Ÿèƒ½ã‚’ç”¨ã„ãŸå‰å‡¦ç†').center())
        _stack_mo_list.append(
            mo.accordion(
                {'è©³ç´°ã‚’é–‹ã': mo.md("""
                * ã“ã“ã§ã¯marimoã®EDAæ©Ÿèƒ½ã§ã‚ã‚‹`mo.ui.dataframe`ã§ã®å‰å‡¦ç†ã‚’å®Ÿæ–½ã§ãã¾ã™ã€‚
                    * ã‚«ãƒ©ãƒ ã®é¸æŠã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒå®Ÿæ–½ã§ãã¾ã™ã€‚
                    * è©³ã—ãã¯å…¬å¼ã‚µã‚¤ãƒˆã‚’ã”è¦§ãã ã•ã„ã€‚
                """).callout('info')
                }
            ))
        _stack_mo_list.append(transformed_df)
    mo.vstack(_stack_mo_list)
    return transformed_df,


@app.cell
def __(READ_DATA, transformed_df):
    if READ_DATA:
        tdf = transformed_df.value.copy()
    return tdf,


@app.cell
def __(READ_DATA, mo, tdf):
    _stack_mo_list = []
    if READ_DATA:
        stats = tdf.describe()
        _stack_mo_list.append(mo.md(
            f"""
            {mo.vstack([mo.md('## ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã‚’å¯è¦–åŒ–')], 'center')}
            {mo.as_html(stats)}"""
        ))
    mo.vstack(_stack_mo_list)
    return stats,


@app.cell
def __(READ_DATA, mo, tdf):
    select_anomaly = None
    _stack_mo_list = []
    if READ_DATA:
        select_anomaly = mo.ui.dropdown(
            [c for c in tdf.columns], value=None
        )
        
        _stack_mo_list = [
            mo.md('### ç•°å¸¸ãƒ•ãƒ©ã‚°ã®é¸æŠ').center(),
            mo.hstack([
                mo.md(f'ç•°å¸¸ãƒ•ãƒ©ã‚°: {select_anomaly}')])
        ]
    mo.vstack(_stack_mo_list)
    return select_anomaly,


@app.cell
def __(select_anomaly):
    ANOMALY_COLUMN = None
    if select_anomaly is not None:
        ANOMALY_COLUMN = select_anomaly.value
    return ANOMALY_COLUMN,


@app.cell
def __(eda_all_data, mo, plot_scatter, select_scatter_columns):
    mo.ui.tabs(
        {
            'âšœï¸ ç•°å¸¸ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ': mo.vstack([
                select_scatter_columns,
                plot_scatter
            ]),
            'ğŸ’¹ å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹EDA': eda_all_data 
        }
    )
    return


@app.cell
def __(READ_DATA, mo, tdf):
    _stack_mo_list = []
    if READ_DATA:
        select_x = mo.ui.dropdown(
            [c for c in tdf.columns], value=tdf.columns[0]
        )
        select_y = mo.ui.dropdown(
            [c for c in tdf.columns], value=tdf.columns[1]
        )
        
        _stack_mo_list = [
            mo.md('### ç•°å¸¸ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ').center(),
            mo.hstack([
                mo.md(f'xè»¸: {select_x}'), mo.md(f'yè»¸: {select_y}')])
        ]
    select_scatter_columns = mo.vstack(_stack_mo_list)
    return select_scatter_columns, select_x, select_y


@app.cell
def __(ANOMALY_COLUMN, READ_DATA, alt, mo, select_x, select_y, tdf):
    chart = None

    _stack_mo_list = []
    if ANOMALY_COLUMN is None:
        _stack_mo_list.append(mo.md('ç•°å¸¸ãƒ•ãƒ©ã‚°ã‚’ç¤ºã™ã‚«ãƒ©ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‰ã®è¨­å®šã§é¸æŠã—ã¦ãã ã•ã„ã€‚').callout('warn'))
    elif READ_DATA & (ANOMALY_COLUMN is not None):
        chart = alt.Chart(tdf).mark_point().encode(
            x=alt.X(select_x.selected_key).scale(zero=False), # Encoding along the x-axis
            y=alt.Y(select_y.selected_key).scale(zero=False), # Encoding along the y-axis
            color=ANOMALY_COLUMN
        )
        
        chart = mo.ui.altair_chart(chart)
        _stack_mo_list.append(mo.md(f'{chart}'))
    plot_scatter = mo.vstack(_stack_mo_list)
    return chart, plot_scatter


@app.cell
def __(READ_DATA, mo, tdf):
    _stack_mo_list = []
    if READ_DATA:
        _stack_mo_list = [
            mo.md('## å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹EDA').center(),
            mo.ui.data_explorer(tdf)]
    eda_all_data = mo.vstack(_stack_mo_list)
    return eda_all_data,


@app.cell
def __(ANOMALY_COLUMN, mo):
    prep_switch = mo.ui.switch(label='å‰å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ï¼', value=False)
    norm_checkbox = mo.ui.checkbox(value=True, label='æ­£è¦åŒ–')
    onehot_checkbox = mo.ui.checkbox(value=True, label='One-Hot Encoding')
    pca_checkbox = mo.ui.checkbox(value=False, label='PCAï¼ˆæ¬¡å…ƒåœ§ç¸®ï¼‰')
    pca_compornents = mo.ui.slider(start=2, stop=10, step=1, label='PCAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆn_compornentsï¼‰')

    _stack_mo_list = [mo.md("""### ç‰¹åˆ¥ãªå‰å‡¦ç†
    * ã“ã“ã§ã¯äº‹å‰ã«å®šç¾©ã•ã‚ŒãŸç‰¹æ®Šãªå‰å‡¦ç†ã‚’é¸ã‚“ã§å®Ÿæ–½ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
    """)]

    if ANOMALY_COLUMN is None:
        _stack_mo_list.append(mo.md('ç•°å¸¸ãƒ•ãƒ©ã‚°ã‚’ç¤ºã™ã‚«ãƒ©ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å‰å‡¦ç†ãŒå®Ÿæ–½ã§ãã¾ã›ã‚“ã€‚å‰ã®è¨­å®šã§é¸æŠã—ã¦ãã ã•ã„ã€‚').callout('warn'))
    else:
        _stack_mo_list += [
            mo.md('å‰å‡¦ç†ã‚’å§‹ã‚ã‚‹å ´åˆã¯è¨­å®šã‚’æ±ºã‚ã¦ä¸‹ã®Switchã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚'),
            norm_checkbox,
            onehot_checkbox,
            mo.hstack([pca_checkbox,pca_compornents]).left(),
            prep_switch,
        ]
    mo.vstack(_stack_mo_list)
    return (
        norm_checkbox,
        onehot_checkbox,
        pca_checkbox,
        pca_compornents,
        prep_switch,
    )


@app.cell
def __(
    ANOMALY_COLUMN,
    PCA,
    StandardScaler,
    norm_checkbox,
    onehot_checkbox,
    pca_checkbox,
    pca_compornents,
    pd,
    prep_switch,
    tdf,
):
    normal_data = None

    if prep_switch.value: 
      # å‰å‡¦ç†å®Ÿè¡Œã‚¹ã‚¤ãƒƒãƒãŒONãªã‚‰ã°ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã«å¾“ã£ã¦ä»¥ä¸‹ã‚’å®Ÿæ–½

        if onehot_checkbox.value:
          # On-hot Encordingã®å‡¦ç†
            tf_df = pd.get_dummies(tdf)
            print('One-hot Encoding')
        
        # æ­£è¦åŒ–ã‚„PCAã¯æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ç”¨ã„ã‚‹ã®ã§å–ã‚Šå‡ºã™
        machine_failure = tf_df[ANOMALY_COLUMN]
        normal_data = tf_df.loc[tf_df[ANOMALY_COLUMN] != 1].drop(ANOMALY_COLUMN, axis=1)
        tf_df = tf_df.drop(ANOMALY_COLUMN, axis=1)

        if norm_checkbox.value:
            # æ­£è¦åŒ–
            scl = StandardScaler()
            # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã ã‘ã§æ­£è¦åŒ–
            normal_data = pd.DataFrame(
                scl.fit_transform(normal_data), columns=normal_data.columns, index=normal_data.index
            )
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
            tf_data = scl.transform(tf_df)
            tf_df = pd.DataFrame(tf_data, columns=tf_df.columns, index=tf_df.index)                      
            print('æ­£è¦åŒ–')

        if pca_checkbox.value:
          # PCAã®å‡¦ç†
            pca = PCA(n_components=pca_compornents.value)
            normal_data = pca.fit_transform(normal_data)
            _columns = tf_df.columns
            tf_data = pca.transform(tf_df)
            tf_df = pd.DataFrame(tf_data, columns=[f'Col_{n}' for n in range(pca_compornents.value)], index=tf_df.index)
        
        # ã‚ã¨ã§ä½¿ã†
        all_data = tf_df
    else:
        print('åœæ­¢ä¸­')
    return all_data, machine_failure, normal_data, pca, scl, tf_data, tf_df


@app.cell
def __(all_data, machine_failure, mo, pd, prep_switch):
    # EDAã«ã¯data_explorerã‚’ä½¿ã†ã€‚å‰å‡¦ç†ãŒè¡Œã‚ã‚Œã¦ã„ãªã„å ´åˆã¯ãŠçŸ¥ã‚‰ã›
    _stack_mo_list = []
    if prep_switch.value: # å‰å‡¦ç†å®Ÿè¡Œã‚¹ã‚¤ãƒƒãƒãŒONãªã‚‰ã°EDAã‚’è¡¨ç¤º
        _stack_mo_list.append(mo.md('## å‰å‡¦ç†å¾Œã®EDA').center())
        _stack_mo_list.append(
            mo.ui.data_explorer(pd.concat([all_data, machine_failure], axis=1))
        )
    else: # å‰å‡¦ç†å®Ÿè¡Œã‚¹ã‚¤ãƒƒãƒãŒOFFãªã‚‰ã°ãŠçŸ¥ã‚‰ã›ã‚’è¡¨ç¤º
        _stack_mo_list.append(mo.md('å‰å‡¦ç†å¾Œã“ã“ã«EDA CellãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚').callout('neutral'))
    prep_after_eda = mo.vstack(_stack_mo_list)
    return prep_after_eda,


@app.cell
def __(all_data, mo, prep_switch):
    _stack_mo_list = []
    if prep_switch.value:
        _obj_data = all_data.select_dtypes(include=object)
        if _obj_data.empty:
            _stack_mo_list.append(
                mo.md('å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼šæ•°å­—ã®ã¿ã§ãƒ‡ãƒ¼ã‚¿ãŒæ§‹æˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å­¦ç¿’ã«é€²ã‚€ã“ã¨ãŒã§ãã¾ã™ï¼').callout(kind="info")
            )
        else:
            _stack_mo_list.append(
                mo.md(f'å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼šæ•°å­—ä»¥å¤–ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼: {_obj_data}').callout(kind="error")
            )
    else:
        _stack_mo_list.append(
                mo.md('å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼šå‰å‡¦ç†å®Ÿè¡Œå¾Œã€ã“ã“ã§å…¥åŠ›ãƒã‚§ãƒƒã‚¯ãŒè¡Œã‚ã‚Œã¾ã™ã€‚').callout(kind="warn")
            )
    validation = mo.vstack(_stack_mo_list)
    return validation,


@app.cell
def __(mo, prep_after_eda, validation):
    mo.ui.tabs({
        'âœ…å‰å‡¦ç†å¾Œã®Validationãƒã‚§ãƒƒã‚¯': validation,
        'ğŸ’¡å‰å‡¦ç†å¾Œã®EDA': prep_after_eda
    })
    return


@app.cell
def __(mo):
    mo.md('---------------------------------')
    return


@app.cell
def __(mo):
    mo.md(
        """# ç•°å¸¸æ¤œçŸ¥ã®ãƒ—ãƒ­ãƒƒãƒˆ
        """
    )
    return


@app.cell
def __(kmeans_setting, knn_setting, mo):
    mo.vstack(
        [
            mo.md('### å­¦ç¿’ã®è¨­å®š').center(),
            mo.ui.tabs(
                {
                'ğŸ§â€â™‚ï¸ KMeans': kmeans_setting,
                'ğŸ§œâ€â™€ï¸ KNN':knn_setting
                }
            ),
            mo.md('--------')
        ]
    )
    return


@app.cell
def __(mo, n_clusters_max_slider, n_neighbors_slider):
    kmeans_setting = mo.md(
        f"""
        * KMeansã§ã¯n_clustersã§ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
        * ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ä»¥ä¸‹ã®è«–æ–‡ã§æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’æ¢ç´¢ã—ã¾ã™ã€‚æ¢ç´¢ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æœ€å¤§å€¤ã‚’ä»¥ä¸‹ã®`n_clusters_max`ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚
            * Stop using the elbow criterion for k-means and how to choose the number of clusters instead (https://arxiv.org/abs/2212.12189)
        {mo.hstack([
            n_clusters_max_slider, 
            mo.md(f'è¨­å®šå€¤: {n_clusters_max_slider.value}')]).left()
        }
        """
    )

    knn_setting = mo.md(
        f"""
        * KNNã§ã¯n_neighborsã§è·é›¢ã‚’æ¸¬ã‚‹è¿‘å‚ç‚¹ã®æ•°ã‚’æ±ºå®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

        {mo.hstack([
            n_neighbors_slider, 
            mo.md(f'è¨­å®šå€¤: {n_neighbors_slider.value}')]).left()
            }
        """
    )
    return kmeans_setting, knn_setting


@app.cell
def __(mo):
    n_clusters_max_slider = mo.ui.slider(start=1, stop=100, step=5, label='n_clusters_max')
    n_neighbors_slider = mo.ui.slider(start=1, stop=30, step=1, label='n_neighbors')
    return n_clusters_max_slider, n_neighbors_slider


@app.cell
def __(mo, normal_data):
    train_switch = mo.ui.switch(value=False)

    _stack_mo_list = [mo.md('## å­¦ç¿’ã®å®Ÿæ–½').center()]

    if normal_data is None:
        _stack_mo_list.append(mo.md('å‰å‡¦ç†ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ãªã„ã®ã§ã€å­¦ç¿’ã‚’å®Ÿæ–½ã§ãã¾ã›ã‚“ã€‚å‰å‡¦ç†ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚').callout('warn'))
    else:
        _stack_mo_list = [
                    mo.md('å­¦ç¿’ã‚’å§‹ã‚ã‚‹å ´åˆã¯è¨­å®šã‚’æ±ºã‚ã¦ä¸‹ã®Run Switchã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚'),
                    train_switch]
    mo.vstack(_stack_mo_list)
    return train_switch,


@app.cell
def __(kmeans_expect_sse_plot, kmeans_scatter_plot, knn_scatter_plot, mo):
    mo.ui.tabs(
        {
            'ğŸ§â€â™‚ï¸ KMeans': mo.vstack([mo.md(
                """## KMeansã§ç•°å¸¸æ¤œçŸ¥
                * ä¸€ç•ªè¿‘ã„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ã®è·é›¢ã§è¨ˆç®—ã™ã‚‹
                """), 
                                   mo.hstack([kmeans_scatter_plot, kmeans_expect_sse_plot])
                                  ]),
            'ğŸ§œâ€â™€ï¸ KNN': mo.vstack([mo.md('## KNNã§ç•°å¸¸æ¤œçŸ¥'), knn_scatter_plot])
        }
    )
    return


@app.cell
def __(
    mo,
    n_clusters_max_slider,
    normal_data,
    plot_expect_sse,
    train_switch,
):
    # å­¦ç¿’ã®å®Ÿæ–½ã¨expect SSEã®è¡¨ç¤ºã€‚
    _stack_mo_list = []
    if train_switch.value:
        n_compornents = n_clusters_max_slider.value
        # å†…éƒ¨ã¯çœç•¥ã™ã‚‹ãŒã€plot_expect_sseã§æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã¨
        # æ•£å¸ƒå›³ãŒè¿”ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹
        ax, last_idx = plot_expect_sse(n_compornents, normal_data)
        _stack_mo_list.append(mo.as_html(ax))
    else:
        _stack_mo_list.append(mo.md('å­¦ç¿’å®Ÿè¡Œå¾Œã«ã“ã“ã«æœ€é©ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚').callout('neutral'))

    kmeans_expect_sse_plot = mo.vstack(_stack_mo_list)
    return ax, kmeans_expect_sse_plot, last_idx, n_compornents


@app.cell
def __(
    KMeans,
    all_data,
    last_idx,
    machine_failure,
    mo,
    normal_data,
    np,
    pd,
    plt,
    train_switch,
):
    _stack_mo_list = []
    if train_switch.value: # å­¦ç¿’ã‚¹ã‚¤ãƒƒãƒãŒONã«ãªã£ãŸã‚‰
        # expect SSEã§è¨ˆç®—ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿æ•°ã§å­¦ç¿’
        kmeans = KMeans(n_clusters=last_idx, random_state=225)
        kmeans.fit(normal_data)
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®é‡å¿ƒã‹ã‚‰ã®è·é›¢ã‚’è¨ˆç®—
        distance = kmeans.transform(all_data)
        # å„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ã‚’äºˆæ¸¬
        predict_labels = kmeans.predict(all_data)
        # æœ€ã‚‚è¿‘ã„ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ã¨ã®è·é›¢ã‚’è¨ˆç®—ã—ã€å„ã‚µãƒ³ãƒ—ãƒ«ã®ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹
        kmeans_anomaly_scores = pd.DataFrame(
            np.array([a[i] for a, i in zip(distance, predict_labels)]), index=all_data.index
        )

        #ã€€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ­ãƒƒãƒˆ
        _normal_index = list(machine_failure.loc[machine_failure == 0].index)
        plt.scatter(_normal_index, kmeans_anomaly_scores.loc[_normal_index])
        # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ­ãƒƒãƒˆ
        _anomaly_index = list(machine_failure.loc[machine_failure == 1].index)
        _ax = plt.scatter(_anomaly_index, kmeans_anomaly_scores.loc[_anomaly_index])
        plt.title('Anomaly Score plot')
        plt.legend(['normal', 'anomaly'])
        # çµæœã‚’ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
        _stack_mo_list.append(mo.as_html(_ax))
    else:
        _stack_mo_list.append(mo.md('å­¦ç¿’å®Ÿè¡Œå¾Œã«ã“ã“ã«ãƒ—ãƒ­ãƒƒãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚').callout('neutral'))
    # çµæœã‚’UI Elementsã¨ã—ã¦å®šç¾©
    kmeans_scatter_plot = mo.vstack(_stack_mo_list)
    return (
        distance,
        kmeans,
        kmeans_anomaly_scores,
        kmeans_scatter_plot,
        predict_labels,
    )


@app.cell
def __(
    NearestNeighbors,
    all_data,
    machine_failure,
    mo,
    n_neighbors_slider,
    normal_data,
    pd,
    plt,
    train_switch,
):
    _stack_mo_list = []
    if train_switch.value: # å­¦ç¿’ã‚¹ã‚¤ãƒƒãƒãŒONãªã‚‰
        # è¨­å®šã—ãŸè¿‘å‚æ•°ã§å­¦ç¿’
        n_neighbors = n_neighbors_slider.value
        knn = NearestNeighbors(n_neighbors=n_neighbors)
        knn.fit(normal_data)
        # è¨­å®šã—ãŸè¿‘å‚ã¨ã®è·é›¢ã‚’è¨ˆç®—ã—ã€ãã®å¹³å‡å€¤ã‚’ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹
        distances, indexes = knn.kneighbors(all_data)
        knn_anomaly_scores = pd.DataFrame(
            distances.mean(axis=1), index=all_data.index)

        # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ­ãƒƒãƒˆ
        _normal_index = list(machine_failure.loc[machine_failure == 0].index)
        plt.scatter(_normal_index, knn_anomaly_scores.loc[_normal_index])
        # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ­ãƒƒãƒˆ
        _anomaly_index = list(machine_failure.loc[machine_failure == 1].index)
        _ax = plt.scatter(_anomaly_index, knn_anomaly_scores.loc[_anomaly_index])
        plt.title('Anomaly Scores')
        plt.legend(['normal', 'anomaly'])
        _stack_mo_list.append(mo.as_html(_ax))
    else:
        _stack_mo_list.append(mo.md('å­¦ç¿’å®Ÿè¡Œå¾Œã«ã“ã“ã«ãƒ—ãƒ­ãƒƒãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚').callout('neutral'))
    # çµæœã‚’UI Elementsã¨ã—ã¦å®šç¾©
    knn_scatter_plot = mo.vstack(_stack_mo_list)
    return (
        distances,
        indexes,
        knn,
        knn_anomaly_scores,
        knn_scatter_plot,
        n_neighbors,
    )


@app.cell
def __():
    from io import StringIO

    import marimo as mo
    import pandas as pd
    import altair as alt
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.cluster import KMeans
    from sklearn.neighbors import NearestNeighbors
    from sklearn.decomposition import PCA
    from sklearn.preprocessing import StandardScaler
    return (
        KMeans,
        NearestNeighbors,
        PCA,
        StandardScaler,
        StringIO,
        alt,
        mo,
        np,
        pd,
        plt,
    )


@app.cell
def __(KMeans, np, plt):
    def plot_expect_sse(n_compornents, df):
        # https://arxiv.org/abs/2212.12189
        # ã„ã„æ„Ÿã˜ã®ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’è¦‹ã‚‹
        sse_list = []
        sse_exp_list = []

        N = df.shape[0]

        for k in range(1, n_compornents+1):

            kmeans = KMeans(n_clusters=k, random_state=18).fit(df)

            # kç•ªç›®ã®æ™‚ã®æœŸå¾…å€¤ã‚’æ ¼ç´
            if k > 1:
                sse_k_hat = ((N-k)/k) * np.min(np.array(sse_list))
            else:
                sse_k_hat = kmeans.inertia_
            sse_exp_list.append(np.sqrt(kmeans.inertia_ / sse_k_hat))

            # kç•ªç›®ã®SSEã‚’æ ¼ç´
            sse_list.append((k/(N-k)) * kmeans.inertia_)

        print(sse_exp_list)

        last_reduction_idx = explore_last_reduction(sse_exp_list)

        # å¯è¦–åŒ–
        plt.hlines(1.0, xmin=0, xmax=n_compornents+1, color="black", linestyle='dashed')
        plt.vlines(last_reduction_idx+1, ymin=sse_exp_list[last_reduction_idx], 
                   ymax=1.0, color="red")
        ax = plt.scatter(range(1, n_compornents+1), sse_exp_list)
        plt.title(f'Expected SSE plot: Optimal n_cluster is {last_reduction_idx+1}')

        print('last reduction: ', last_reduction_idx+1)

        return ax, last_reduction_idx+1

    def explore_last_reduction(sse_exp_list):
        # 1.0ã‚’è¶…ãˆã‚‹ç›´å‰ã®indexã‚’è¿”ã™
        last_index = 0
        for i, e in enumerate(sse_exp_list):
            if (i > 1) & (e > 1.0) & (sse_exp_list[i-1] < 1.0):
                last_index = i-1
        return last_index
    return explore_last_reduction, plot_expect_sse


if __name__ == "__main__":
    app.run()
